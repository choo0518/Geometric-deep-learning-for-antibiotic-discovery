{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Pytorch geometric\n",
    "import torch   \n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.nn import Linear, CrossEntropyLoss, BCELoss\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool as gap,  global_max_pool as gmp\n",
    "\n",
    "#rdkit\n",
    "from rdkit import Chem                      \n",
    "from rdkit.Chem import GetAdjacencyMatrix       \n",
    "from scipy.sparse import coo_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#sklearn\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#shuffle\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onek_encoding_unk(value, choices):\n",
    "    \"\"\"\n",
    "    Creates a one-hot encoding with an extra category for uncommon values.\n",
    "\n",
    "    :param value: The value for which the encoding should be one.\n",
    "    :param choices: A list of possible values.\n",
    "    :return: A one-hot encoding of the :code:`value` in a list of length :code:`len(choices) + 1`.\n",
    "             If :code:`value` is not in :code:`choices`, then the final element in the encoding is -1.\n",
    "    \"\"\"\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Featurization_parameters:\n",
    "    \"\"\"\n",
    "    A class holding molecule featurization parameters as attributes.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        # Atom feature sizes\n",
    "        self.MAX_ATOMIC_NUM = 100\n",
    "        #for one-hot-encoding\n",
    "        self.ATOM_FEATURES = {\n",
    "            'atomic_num': list(range(self.MAX_ATOMIC_NUM)),\n",
    "            'degree': [0, 1, 2, 3, 4, 5],\n",
    "            'formal_charge': [-1, -2, 1, 2, 0],\n",
    "            'chiral_tag': [0, 1, 2, 3],\n",
    "            'num_Hs': [0, 1, 2, 3, 4],\n",
    "            'hybridization': [\n",
    "                Chem.rdchem.HybridizationType.SP,\n",
    "                Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3,\n",
    "                Chem.rdchem.HybridizationType.SP3D,\n",
    "                Chem.rdchem.HybridizationType.SP3D2\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        # Distance feature sizes\n",
    "        self.PATH_DISTANCE_BINS = list(range(10))\n",
    "        self.THREE_D_DISTANCE_MAX = 20\n",
    "        self.THREE_D_DISTANCE_STEP = 1\n",
    "        self.THREE_D_DISTANCE_BINS = list(range(0, self.THREE_D_DISTANCE_MAX + 1, self.THREE_D_DISTANCE_STEP))\n",
    "\n",
    "        # len(choices) + 1 to include room for uncommon values; + 2 at end for IsAromatic and mass\n",
    "        self.ATOM_FDIM = sum(len(choices) + 1 for choices in self.ATOM_FEATURES.values()) + 2\n",
    "        self.EXTRA_ATOM_FDIM = 0\n",
    "        self.BOND_FDIM = 14\n",
    "        self.EXTRA_BOND_FDIM = 0\n",
    "        self.REACTION_MODE = None\n",
    "        self.EXPLICIT_H = False\n",
    "        self.REACTION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = Featurization_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom: Chem.rdchem.Atom, functional_groups=None):\n",
    "    \"\"\"\n",
    "    Builds a feature vector for an atom.\n",
    "\n",
    "    :param atom: An RDKit atom.\n",
    "    :param functional_groups: A k-hot vector indicating the functional groups the atom belongs to.\n",
    "    :return: A list containing the atom features.\n",
    "    \"\"\"\n",
    "    if atom is None:\n",
    "        features = [0] * PARAMS.ATOM_FDIM\n",
    "    else:\n",
    "        features = onek_encoding_unk(atom.GetAtomicNum() - 1, PARAMS.ATOM_FEATURES['atomic_num']) + \\\n",
    "            onek_encoding_unk(atom.GetTotalDegree(), PARAMS.ATOM_FEATURES['degree']) + \\\n",
    "            onek_encoding_unk(atom.GetFormalCharge(), PARAMS.ATOM_FEATURES['formal_charge']) + \\\n",
    "            onek_encoding_unk(int(atom.GetChiralTag()), PARAMS.ATOM_FEATURES['chiral_tag']) + \\\n",
    "            onek_encoding_unk(int(atom.GetTotalNumHs()), PARAMS.ATOM_FEATURES['num_Hs']) + \\\n",
    "            onek_encoding_unk(int(atom.GetHybridization()), PARAMS.ATOM_FEATURES['hybridization']) + \\\n",
    "            [1 if atom.GetIsAromatic() else 0] + \\\n",
    "            [atom.GetMass() * 0.01]  # scaled to about the same range as other features\n",
    "        if functional_groups is not None:\n",
    "            features += functional_groups\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bond_features(bond: Chem.rdchem.Bond):\n",
    "    \"\"\"\n",
    "    Builds a feature vector for a bond.\n",
    "\n",
    "    :param bond: An RDKit bond.\n",
    "    :return: A list containing the bond features.\n",
    "    \"\"\"\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (PARAMS.BOND_FDIM - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            (bond.GetIsConjugated() if bt is not None else 0),\n",
    "            (bond.IsInRing() if bt is not None else 0)\n",
    "        ]\n",
    "        fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    return fbond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MORGAN_RADIUS = 2\n",
    "MORGAN_NUM_BITS = 2048\n",
    "#a vector representation (1x2048) for molecular feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morgan_binary_features_generator(mol,\n",
    "                                     radius: int = MORGAN_RADIUS,\n",
    "                                     num_bits: int = MORGAN_NUM_BITS):\n",
    "    \"\"\"\n",
    "    Generates a binary Morgan fingerprint for a molecule.\n",
    "    :param mol: A molecule (i.e., either a SMILES or an RDKit molecule).\n",
    "    :param radius: Morgan fingerprint radius.\n",
    "    :param num_bits: Number of bits in Morgan fingerprint.\n",
    "    :return: A 1D numpy array containing the binary Morgan fingerprint.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(mol) if type(mol) == str else mol\n",
    "    features_vec = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n",
    "    features = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(features_vec, features)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset,batch_size):\n",
    "    SMILES = dataset['SMILES']\n",
    "    data_list = []\n",
    "    for smiles in SMILES:\n",
    "        mol = Chem.MolFromSmiles(smiles)     \n",
    "        mol = Chem.AddHs(mol)  \n",
    "\n",
    "        #generate a global vector features (binary Morgan fingerprint) and convert them\n",
    "        mol_feature = torch.tensor(np.array(morgan_binary_features_generator(mol)))\n",
    "\n",
    "        xs = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            x = atom_features(atom)\n",
    "            xs.append(x)\n",
    "            \n",
    "        x = torch.tensor(np.array(xs))\n",
    "        \n",
    "        edge_indices, edge_attrs = [], []\n",
    "        \n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "    \n",
    "            e = bond_features(bond)\n",
    "\n",
    "            edge_indices += [[i,j],[j,i]]\n",
    "            edge_attrs += [e, e]\n",
    "        \n",
    "        edge_index = torch.tensor(edge_indices)\n",
    "        edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "        edge_attr = torch.tensor(edge_attrs).view(-1, 14)\n",
    "        \n",
    "        y = torch.tensor(int(dataset.loc[dataset['SMILES'] == smiles,'Activity'])) #response variable y\n",
    "\n",
    "        smi = smiles\n",
    "\n",
    "        # add smiles and num_feature as the attributes\n",
    "        data = Data(x=x, y=y, edge_index=edge_index,edge_attr = edge_attr, smiles=smi, mol_feature=mol_feature)  \n",
    "        data_list.append(data)   # store processed data into the list\n",
    "        \n",
    "    return DataLoader(data_list,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        print(f'Reset trainable parameters of layer = {layer}')\n",
    "        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,train_loader):\n",
    "    \n",
    "    model.train()   \n",
    "    running_loss = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = BCELoss()\n",
    "    for batch in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        label = batch.y.view(-1,1)\n",
    "        loss = criterion(outputs.float(),label.float())\n",
    "        \n",
    "\n",
    "        loss.backward()   # Compute the gradient of loss function \n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        running_loss += loss.item()\n",
    "        # probability that is larger than 0.5, classify as 1 \n",
    "\n",
    "        pred = (outputs >= 0.5).float()\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += (pred == label).float().sum()\n",
    "        \n",
    "    \n",
    "    loss = running_loss/len(train_loader)\n",
    "    accuracy = 100*correct/total\n",
    "    \n",
    "    train_accuracy.append(accuracy)\n",
    "    train_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: '+str(int(epoch)))\n",
    "        print('Train Loss: %.3f | Accuracy: %.3f'%(loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        criterion = BCELoss()\n",
    "        for batch in test_loader:\n",
    "        \n",
    "            outputs = model(batch)\n",
    "            label = batch.y.view(-1,1)\n",
    "\n",
    "            loss = criterion(outputs.float(), label.float())    \n",
    "            running_loss += loss.item()\n",
    "            # probability that is larger than 0.5, classify as 1 \n",
    "            pred = (outputs >= 0.5).float()\n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (pred == label).float().sum()\n",
    "    \n",
    "        loss = running_loss/len(test_loader)\n",
    "        accuracy = 100*correct/total\n",
    "    \n",
    "        test_accuracy.append(accuracy)\n",
    "        test_loss.append(loss)\n",
    "        if epoch % 10 == 0:\n",
    "            print('Test Loss: %.3f | Accuracy: %.3f'%(loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set as a whole loader\n",
    "def test_metrics(test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        labels = []\n",
    "        preds = []\n",
    "        for batch in test_loader:\n",
    "            \n",
    "            labels += list(batch.y.view(-1,1).numpy())\n",
    "            preds += list(model(batch).detach().numpy())\n",
    "        \n",
    "        pred_labels = [1 if i > 0.5 else 0 for i in preds]\n",
    "        auc = roc_auc_score(list(labels), list(preds), average='weighted')\n",
    "        report = classification_report(labels, pred_labels,output_dict=True)\n",
    "        return auc, report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metrics):\n",
    "    AUC = [] \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    accuracy = []\n",
    "    for i in metrics:\n",
    "        AUC.append(i[0])\n",
    "        precision.append(i[1]['weighted avg']['precision'])\n",
    "        recall.append(i[1]['weighted avg']['recall'])\n",
    "        f1_score.append(i[1]['weighted avg']['f1-score'])\n",
    "        accuracy.append(i[1]['accuracy'])\n",
    "    \n",
    "    print('AUC:',np.mean(AUC),'+/-',np.std(AUC))\n",
    "    print('Accuracy:',np.mean(accuracy),'+/-',np.std(accuracy))\n",
    "    print('Precision:',np.mean(precision),'+/-',np.std(precision))\n",
    "    print('Recall:',np.mean(recall),'+/-',np.std(recall))\n",
    "    print('F1-score:',np.mean(f1_score),'+/-',np.std(f1_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction\n",
    "\n",
    "#### 1. GAT layer to update node(atom) feature vector of a graph(modelcue).\n",
    "#### 2. Aggregate the updated node feature vector to capture global property\n",
    "####     i.e. apply global_mean_pool function over the node features \n",
    "#### 3. Concatnate the aggregated local features with binary morgan fingerprint. This vector will be the predictors of the model. \n",
    "#### 4. Then pass the processed features to a fully connected layer for binary classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden + 2048, 2048)\n",
    "        self.linear2 = Linear(2048, 50)\n",
    "        self.linear3 = Linear(50, 10)\n",
    "        self.linear4 = Linear(10, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature        \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "\n",
    "        x = self.conv1(x,edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        # now train a fully connected graph classification network  \n",
    "        x = F.relu(self.linear1(x))            \n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAT model training and evalutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/jimmy/Desktop/FYP/training_data.csv')\n",
    "df = df[['SMILES','Activity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/jimmy/Desktop/FYP/training_data.csv')\n",
    "pos = df[df['Activity'] == 1]\n",
    "neg = df[df['Activity'] == 0]\n",
    "\n",
    "# postivie: negative = 1: 3\n",
    "full = pd.concat([neg.sample(3*len(pos)),pos])\n",
    "full = full[['SMILES','Activity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.615 | Accuracy: 63.802\n",
      "Test Loss: 0.472 | Accuracy: 75.000\n",
      "Validation loss decreased (inf --> 0.472192).  Saving model ...\n",
      "Validation loss decreased (0.472192 --> 0.361444).  Saving model ...\n",
      "Validation loss decreased (0.361444 --> 0.337647).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation loss decreased (0.337647 --> 0.336577).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.027 | Accuracy: 99.479\n",
      "Test Loss: 0.519 | Accuracy: 88.542\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.726 | Accuracy: 36.979\n",
      "Test Loss: 0.623 | Accuracy: 81.250\n",
      "Validation loss decreased (inf --> 0.622874).  Saving model ...\n",
      "Validation loss decreased (0.622874 --> 0.419103).  Saving model ...\n",
      "Validation loss decreased (0.419103 --> 0.402375).  Saving model ...\n",
      "Validation loss decreased (0.402375 --> 0.372762).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.014 | Accuracy: 100.000\n",
      "Test Loss: 0.500 | Accuracy: 86.458\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.603 | Accuracy: 75.000\n",
      "Test Loss: 0.502 | Accuracy: 75.000\n",
      "Validation loss decreased (inf --> 0.502186).  Saving model ...\n",
      "Validation loss decreased (0.502186 --> 0.416901).  Saving model ...\n",
      "Validation loss decreased (0.416901 --> 0.415707).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.028 | Accuracy: 99.479\n",
      "Test Loss: 0.582 | Accuracy: 84.375\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.655 | Accuracy: 61.719\n",
      "Test Loss: 0.554 | Accuracy: 75.000\n",
      "Validation loss decreased (inf --> 0.553795).  Saving model ...\n",
      "Validation loss decreased (0.553795 --> 0.431433).  Saving model ...\n",
      "Validation loss decreased (0.431433 --> 0.380368).  Saving model ...\n",
      "Validation loss decreased (0.380368 --> 0.313672).  Saving model ...\n",
      "Validation loss decreased (0.313672 --> 0.299736).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.027 | Accuracy: 99.479\n",
      "Test Loss: 0.394 | Accuracy: 91.667\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.691 | Accuracy: 48.698\n",
      "Test Loss: 0.610 | Accuracy: 75.000\n",
      "Validation loss decreased (inf --> 0.610403).  Saving model ...\n",
      "Validation loss decreased (0.610403 --> 0.488548).  Saving model ...\n",
      "Validation loss decreased (0.488548 --> 0.426714).  Saving model ...\n",
      "Validation loss decreased (0.426714 --> 0.425382).  Saving model ...\n",
      "Validation loss decreased (0.425382 --> 0.386975).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.043 | Accuracy: 98.438\n",
      "Test Loss: 0.555 | Accuracy: 85.417\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(full['SMILES'],full['Activity']):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = full.iloc[train_idx]\n",
    "    test_set = full.iloc[test_idx]\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().double()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8778935185185187 +/- 0.02477230414130137\n",
      "Accuracy: 0.8791666666666668 +/- 0.019320038532282726\n",
      "Precision: 0.8771581731278764 +/- 0.018817928938836766\n",
      "Recall: 0.8791666666666668 +/- 0.019320038532282726\n",
      "F1-score: 0.8770742994705367 +/- 0.018495409930806166\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postivie: negative = 1: 5\n",
    "full = pd.concat([neg.sample(5*len(pos)),pos])\n",
    "full = full[['SMILES','Activity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.638 | Accuracy: 53.472\n",
      "Test Loss: 0.431 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.431129).  Saving model ...\n",
      "Validation loss decreased (0.431129 --> 0.314351).  Saving model ...\n",
      "Validation loss decreased (0.314351 --> 0.295263).  Saving model ...\n",
      "Validation loss decreased (0.295263 --> 0.277856).  Saving model ...\n",
      "Validation loss decreased (0.277856 --> 0.269210).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.036 | Accuracy: 99.306\n",
      "Test Loss: 0.381 | Accuracy: 88.194\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.562 | Accuracy: 74.479\n",
      "Test Loss: 0.430 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.430468).  Saving model ...\n",
      "Validation loss decreased (0.430468 --> 0.310840).  Saving model ...\n",
      "Validation loss decreased (0.310840 --> 0.263486).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.020 | Accuracy: 99.653\n",
      "Test Loss: 0.434 | Accuracy: 89.583\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.481 | Accuracy: 78.125\n",
      "Test Loss: 0.356 | Accuracy: 86.111\n",
      "Validation loss decreased (inf --> 0.356238).  Saving model ...\n",
      "Validation loss decreased (0.356238 --> 0.301548).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.019 | Accuracy: 99.479\n",
      "Test Loss: 0.479 | Accuracy: 86.806\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.524 | Accuracy: 79.861\n",
      "Test Loss: 0.386 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.386465).  Saving model ...\n",
      "Validation loss decreased (0.386465 --> 0.293546).  Saving model ...\n",
      "Validation loss decreased (0.293546 --> 0.266575).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.034 | Accuracy: 98.958\n",
      "Test Loss: 0.447 | Accuracy: 89.583\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.558 | Accuracy: 68.056\n",
      "Test Loss: 0.371 | Accuracy: 86.111\n",
      "Validation loss decreased (inf --> 0.371123).  Saving model ...\n",
      "Validation loss decreased (0.371123 --> 0.309506).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.309506 --> 0.290659).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.044 | Accuracy: 98.785\n",
      "Test Loss: 0.382 | Accuracy: 90.972\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(full['SMILES'],full['Activity']):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = full.iloc[train_idx]\n",
    "    test_set = full.iloc[test_idx]\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().double()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8927083333333334 +/- 0.015782386357449284\n",
      "Accuracy: 0.9083333333333334 +/- 0.009212846639876114\n",
      "Precision: 0.9055531341326818 +/- 0.010170564715767197\n",
      "Recall: 0.9083333333333334 +/- 0.009212846639876114\n",
      "F1-score: 0.9013563897466771 +/- 0.009666139175034885\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postivie: negative = 1: 10\n",
    "full = pd.concat([neg.sample(10*len(pos)),pos])\n",
    "full = full[['SMILES','Activity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.483 | Accuracy: 71.875\n",
      "Test Loss: 0.324 | Accuracy: 90.909\n",
      "Validation loss decreased (inf --> 0.324160).  Saving model ...\n",
      "Validation loss decreased (0.324160 --> 0.235950).  Saving model ...\n",
      "Validation loss decreased (0.235950 --> 0.197766).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.035 | Accuracy: 98.958\n",
      "Test Loss: 0.265 | Accuracy: 93.939\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.465 | Accuracy: 78.598\n",
      "Test Loss: 0.274 | Accuracy: 90.909\n",
      "Validation loss decreased (inf --> 0.274463).  Saving model ...\n",
      "Validation loss decreased (0.274463 --> 0.228605).  Saving model ...\n",
      "Validation loss decreased (0.228605 --> 0.213572).  Saving model ...\n",
      "Validation loss decreased (0.213572 --> 0.213081).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.047 | Accuracy: 98.011\n",
      "Test Loss: 0.268 | Accuracy: 93.939\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.390 | Accuracy: 90.909\n",
      "Test Loss: 0.269 | Accuracy: 90.909\n",
      "Validation loss decreased (inf --> 0.268577).  Saving model ...\n",
      "Validation loss decreased (0.268577 --> 0.201768).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation loss decreased (0.201768 --> 0.184656).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.056 | Accuracy: 98.295\n",
      "Test Loss: 0.304 | Accuracy: 93.939\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.358 | Accuracy: 86.458\n",
      "Test Loss: 0.197 | Accuracy: 93.939\n",
      "Validation loss decreased (inf --> 0.196699).  Saving model ...\n",
      "Validation loss decreased (0.196699 --> 0.172199).  Saving model ...\n",
      "Validation loss decreased (0.172199 --> 0.147301).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.021 | Accuracy: 99.432\n",
      "Test Loss: 0.224 | Accuracy: 93.939\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.381 | Accuracy: 90.909\n",
      "Test Loss: 0.266 | Accuracy: 90.909\n",
      "Validation loss decreased (inf --> 0.266066).  Saving model ...\n",
      "Validation loss decreased (0.266066 --> 0.212879).  Saving model ...\n",
      "Validation loss decreased (0.212879 --> 0.200861).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.046 | Accuracy: 98.580\n",
      "Test Loss: 0.275 | Accuracy: 93.939\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "#AUC\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(full['SMILES'],full['Activity']):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = full.iloc[train_idx]\n",
    "    test_set = full.iloc[test_idx]\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().double()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8765277777777778 +/- 0.0340446740930933\n",
      "Accuracy: 0.9431818181818181 +/- 0.011236664374387388\n",
      "Precision: 0.9414939578212858 +/- 0.011038968128222656\n",
      "Recall: 0.9431818181818181 +/- 0.011236664374387388\n",
      "F1-score: 0.9394156232890758 +/- 0.01172392990927586\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120:2215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = df[['SMILES','Activity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.273 | Accuracy: 89.507\n",
      "Test Loss: 0.140 | Accuracy: 95.503\n",
      "Validation loss decreased (inf --> 0.140281).  Saving model ...\n",
      "Validation loss decreased (0.140281 --> 0.122213).  Saving model ...\n",
      "Validation loss decreased (0.122213 --> 0.117680).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.117680 --> 0.116004).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.048 | Accuracy: 98.233\n",
      "Test Loss: 0.141 | Accuracy: 96.574\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.235 | Accuracy: 91.809\n",
      "Test Loss: 0.145 | Accuracy: 96.360\n",
      "Validation loss decreased (inf --> 0.144823).  Saving model ...\n",
      "Validation loss decreased (0.144823 --> 0.140078).  Saving model ...\n",
      "Validation loss decreased (0.140078 --> 0.136677).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.036 | Accuracy: 98.662\n",
      "Test Loss: 0.176 | Accuracy: 97.430\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.271 | Accuracy: 91.381\n",
      "Test Loss: 0.164 | Accuracy: 95.289\n",
      "Validation loss decreased (inf --> 0.163862).  Saving model ...\n",
      "Validation loss decreased (0.163862 --> 0.133990).  Saving model ...\n",
      "Validation loss decreased (0.133990 --> 0.128455).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.128455 --> 0.122838).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.055 | Accuracy: 98.448\n",
      "Test Loss: 0.133 | Accuracy: 96.360\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Validation loss decreased (0.122838 --> 0.120612).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.015 | Accuracy: 99.465\n",
      "Test Loss: 0.140 | Accuracy: 96.360\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.267 | Accuracy: 94.861\n",
      "Test Loss: 0.146 | Accuracy: 94.861\n",
      "Validation loss decreased (inf --> 0.145750).  Saving model ...\n",
      "Validation loss decreased (0.145750 --> 0.121814).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.121814 --> 0.108937).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.042 | Accuracy: 98.608\n",
      "Test Loss: 0.124 | Accuracy: 96.360\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=2048, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=2048, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.211 | Accuracy: 94.861\n",
      "Test Loss: 0.152 | Accuracy: 94.861\n",
      "Validation loss decreased (inf --> 0.152242).  Saving model ...\n",
      "Validation loss decreased (0.152242 --> 0.151500).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.066 | Accuracy: 94.861\n",
      "Test Loss: 0.189 | Accuracy: 94.861\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jimmy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jimmy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "#AUC\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(full['SMILES'],full['Activity']):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = full.iloc[train_idx]\n",
    "    test_set = full.iloc[test_idx]\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().double()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8897479307750189 +/- 0.037739490081784656\n",
      "Accuracy: 0.9635974304068521 +/- 0.007896826087617052\n",
      "Precision: 0.9523966240201037 +/- 0.026404948150059563\n",
      "Recall: 0.9635974304068521 +/- 0.007896826087617052\n",
      "F1-score: 0.9570415279908652 +/- 0.017070480279998915\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
